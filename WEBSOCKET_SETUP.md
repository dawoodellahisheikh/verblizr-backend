# WebSocket Live Interpretation Setup\n\n## 🚀 Quick Start\n\n### 1. Install WebSocket Dependencies\n```bash\ncd /Users/dawoodsheikh/MOBILEAPPS/VERBLIZR/BACKEND\nnpm install\n```\n\n### 2. Start Both Servers\n```bash\n# Start both HTTP (4000) and WebSocket (8082) servers\nnpm start\n\n# Or for development with auto-restart\nnpm run dev\n```\n\n### 3. Test the Setup\n```bash\n# Test HTTP API\ncurl http://localhost:4000/health\n\n# Test WebSocket (in another terminal)\nwscat ws://localhost:8082\n```\n\n## 📋 What's Now Working\n\n### ✅ **Backend Services**\n- **HTTP API Server** (port 4000)\n  - TTS endpoints: `/api/tts/*`\n  - OpenAI endpoints: `/api/openai/*`\n  - GCP endpoints: `/api/gcp/*`\n  - Authentication & billing\n\n- **WebSocket Server** (port 8082)\n  - Real-time audio processing\n  - Speech-to-text (OpenAI Whisper)\n  - Translation (Google Translate + OpenAI GPT fallback)\n  - Session management\n  - VAD support\n\n### ✅ **Frontend Integration**\n- `useTurnInterpreter` connects to WebSocket\n- Real-time conversation flow\n- Audio streaming and processing\n- TTS playback coordination\n\n## 🔧 Available Scripts\n\n```bash\n# Start both servers together\nnpm start\nnpm run dev\n\n# Start servers individually\nnpm run start:http      # HTTP API only (port 4000)\nnpm run start:websocket # WebSocket only (port 8082)\nnpm run dev:http        # HTTP API with auto-restart\nnpm run dev:websocket   # WebSocket with auto-restart\n```\n\n## 🎯 Testing the Live Interpretation\n\n1. **Start the backend:**\n   ```bash\n   cd /Users/dawoodsheikh/MOBILEAPPS/VERBLIZR/BACKEND\n   npm start\n   ```\n\n2. **Start the React Native app:**\n   ```bash\n   cd /Users/dawoodsheikh/MOBILEAPPS/VERBLIZR/FRONTEND\n   npx react-native run-ios\n   ```\n\n3. **Test the live interpretation:**\n   - Open the InterpretationScreen in the app\n   - Tap the microphone to start\n   - The app should connect to `ws://localhost:8082`\n   - Audio will be processed in real-time\n\n## 🛠 Architecture Overview\n\n```\nReact Native App (Frontend)\n        |\n        | WebSocket Connection\n        |\n        v\nWebSocket Server (port 8082)\n        |\n        | Processes Audio Chunks\n        |\n        v\n   [OpenAI Whisper] → [Google Translate] → [Response]\n        ↑                     ↑\n        |                     |\n   HTTP API Server (port 4000)\n```\n\n## 🔊 Audio Processing Flow\n\n1. **Frontend** captures audio → converts to PCM16LE → sends via WebSocket\n2. **WebSocket Server** receives audio chunks → buffers → creates WAV\n3. **OpenAI Whisper** transcribes audio → returns text\n4. **Translation Service** (Google/OpenAI) translates text\n5. **WebSocket Server** sends result back to frontend\n6. **Frontend** plays TTS translation\n\n## 🌍 Language Support\n\nSupported languages: `en`, `es`, `fr`, `de`, `it`, `pt`, `ru`, `ja`, `ko`, `zh`, `hi`, `ar`, `ur`, `tr`, `pl`, `nl`, `sv`, `da`, `no`, `fi`\n\n## 🚨 Troubleshooting\n\n### WebSocket Connection Issues\n- Check that port 8082 is not blocked\n- Verify the backend is running: `curl http://localhost:4000/health`\n- Check WebSocket connection: Use a WebSocket client to test `ws://localhost:8082`\n\n### Audio Processing Issues\n- Ensure OpenAI API key is valid in `.env`\n- Check Google Cloud credentials are properly configured\n- Monitor logs for processing errors\n\n### Frontend Connection Issues\n- iOS Simulator: Uses `ws://localhost:8082`\n- Android Emulator: Uses `ws://10.0.2.2:8082`\n- Check frontend `useTurnInterpreter.tsx` for correct URLs\n\n## 🎉 Success Indicators\n\nWhen everything is working, you should see:\n\n### Backend Logs:\n```\n🚀 Verblizr API Server running on http://localhost:4000\n🎙️ [WebSocket] Live interpretation server started on ws://localhost:8082\n🎯 [WebSocket] Ready to handle live interpretation requests\n```\n\n### Frontend Behavior:\n- InterpretationScreen loads without errors\n- Microphone button works (starts recording)\n- Conversation flow indicator shows states\n- Audio levels are displayed\n- Translations appear in conversation history\n\n## 📈 Next Steps\n\n1. **Test with Real Audio** (if audio libs are working)\n2. **Fine-tune Translation Quality**\n3. **Add Language Detection Improvements**\n4. **Performance Optimization**\n5. **Production Deployment**